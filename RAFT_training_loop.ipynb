{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "58cf4bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import argparse\n",
    "import os\n",
    "# import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe3fa7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAFT_master.core.raft import RAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "caa6d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from RAFT_master import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32722a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude extremly large displacements\n",
    "MAX_FLOW = 400\n",
    "# SUM_FREQ = 100\n",
    "# VAL_FREQ = 5000\n",
    "\n",
    "def sequence_loss(flow_preds, flow_gt, valid, gamma=0.8, max_flow=MAX_FLOW):\n",
    "    \"\"\" Loss function defined over sequence of flow predictions \"\"\"\n",
    "\n",
    "    n_predictions = len(flow_preds)    \n",
    "    flow_loss = 0.0\n",
    "\n",
    "    # exlude invalid pixels and extremely large diplacements\n",
    "    mag = torch.sum(flow_gt**2, dim=1).sqrt()\n",
    "    valid = (valid >= 0.5) & (mag < max_flow)\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        i_weight = gamma**(n_predictions - i - 1)\n",
    "        i_loss = (flow_preds[i] - flow_gt).abs()\n",
    "        flow_loss += i_weight * (valid[:, None] * i_loss).mean()\n",
    "\n",
    "    epe = torch.sum((flow_preds[-1] - flow_gt)**2, dim=1).sqrt()\n",
    "    epe = epe.view(-1)[valid.view(-1)]\n",
    "\n",
    "    metrics = {\n",
    "        'epe': epe.mean().item(),\n",
    "        '1px': (epe < 1).float().mean().item(),\n",
    "        '3px': (epe < 3).float().mean().item(),\n",
    "        '5px': (epe < 5).float().mean().item(),\n",
    "    }\n",
    "\n",
    "    return flow_loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =0.00002\n",
    "num_steps = 100000\n",
    "batch_size = 6\n",
    "image_size =[384, 512]\n",
    "#     parser.add_argument('--gpus', type=int, nargs='+', default=[0,1])\n",
    "#     parser.add_argument('--mixed_precision', action='store_true', help='use mixed precision')\n",
    "iters = 12\n",
    "wdecay = .00005\n",
    "epsilon = 1e-8\n",
    "clip = 1.0\n",
    "dropout = 0.0\n",
    "gamma = 0.8 # exponential weighting\n",
    "#     parser.add_argument('--add_noise', action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid = (flow[0].abs() < 1000) & (flow[1].abs() < 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54483c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RAFT()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wdecay, eps=epsilon))\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr, num_steps+100, pct_start=0.05, cycle_momentum=False, anneal_strategy='linear')\n",
    "model = model.to(device)\n",
    "\n",
    "total_steps = 0\n",
    "scaler = GradScaler(enabled=args.mixed_precision\n",
    "                    \n",
    "VAL_FREQ = 5000\n",
    "add_noise = True\n",
    "\n",
    "total_steps = 0\n",
    "scaler = GradScaler(enabled=args.mixed_precision)\n",
    "VAL_FREQ = 5000\n",
    "add_noise = True\n",
    "\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch\", str(epoch) + \": \", end=\"\")\n",
    "    epoch_loss = 0.0\n",
    "    for i_batch, data_blob in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        image1, image2, flow, valid = [x.cuda() for x in data_blob]\n",
    "\n",
    "        if args.add_noise:\n",
    "            stdv = np.random.uniform(0.0, 5.0)\n",
    "            image1 = (image1 + stdv * torch.randn(*image1.shape).cuda()).clamp(0.0, 255.0)\n",
    "            image2 = (image2 + stdv * torch.randn(*image2.shape).cuda()).clamp(0.0, 255.0)\n",
    "\n",
    "        flow_predictions = model(image1, image2, iters=iters)            \n",
    "\n",
    "        loss, metrics = sequence_loss(flow_predictions, flow, valid, gamma)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)                \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scheduler.step()\n",
    "        scaler.update()\n",
    "\n",
    "#         if total_steps % VAL_FREQ == VAL_FREQ - 1:\n",
    "#             PATH = 'checkpoints/%d_%s.pth' % (total_steps+1, args.name)\n",
    "#             torch.save(model.state_dict(), PATH)\n",
    "\n",
    "#             results = {}\n",
    "#             for val_dataset in args.validation:\n",
    "#                 if val_dataset == 'chairs':\n",
    "#                     results.update(evaluate.validate_chairs(model.module))\n",
    "#                 elif val_dataset == 'sintel':\n",
    "#                     results.update(evaluate.validate_sintel(model.module))\n",
    "#                 elif val_dataset == 'kitti':\n",
    "#                     results.update(evaluate.validate_kitti(model.module))\n",
    "\n",
    "#             logger.write_dict(results)\n",
    "\n",
    "#             model.train()\n",
    "#             if args.stage != 'chairs':\n",
    "#                 model.module.freeze_bn()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        print(\"Loss:\", epoch_loss)\n",
    "        losses.append(epoch_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "cs231n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
