{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57db2318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cs231n/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259287b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_loss(flow_preds, flow_gt, valid_flow_mask, gamma=0.8, max_flow=400):\n",
    "    \"\"\"Loss function defined over sequence of flow predictions\"\"\"\n",
    "\n",
    "    if gamma > 1:\n",
    "        raise ValueError(f\"Gamma should be < 1, got {gamma}.\")\n",
    "\n",
    "    # exlude invalid pixels and extremely large diplacements\n",
    "    flow_norm = torch.sum(flow_gt ** 2, dim=1).sqrt()\n",
    "    valid_flow_mask = valid_flow_mask & (flow_norm < max_flow)\n",
    "\n",
    "    valid_flow_mask = valid_flow_mask[:, None, :, :]\n",
    "\n",
    "    flow_preds = torch.stack(flow_preds)  # shape = (num_flow_updates, batch_size, 2, H, W)\n",
    "\n",
    "    abs_diff = (flow_preds - flow_gt).abs()\n",
    "    abs_diff = (abs_diff * valid_flow_mask).mean(axis=(1, 2, 3, 4))\n",
    "\n",
    "    num_predictions = flow_preds.shape[0]\n",
    "    weights = gamma ** torch.arange(num_predictions - 1, -1, -1).to(flow_gt.device)\n",
    "    flow_loss = (abs_diff * weights).sum()\n",
    "\n",
    "    return flow_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39514f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(flow_pred, flow_gt, valid_flow_mask=None):\n",
    "\n",
    "    epe = ((flow_pred - flow_gt) ** 2).sum(dim=1).sqrt()\n",
    "    flow_norm = (flow_gt ** 2).sum(dim=1).sqrt()\n",
    "\n",
    "    if valid_flow_mask is not None:\n",
    "        epe = epe[valid_flow_mask]\n",
    "        flow_norm = flow_norm[valid_flow_mask]\n",
    "\n",
    "    relative_epe = epe / flow_norm\n",
    "\n",
    "    metrics = {\n",
    "        \"epe\": epe.mean().item(),\n",
    "        \"1px\": (epe < 1).float().mean().item(),\n",
    "        \"3px\": (epe < 3).float().mean().item(),\n",
    "        \"5px\": (epe < 5).float().mean().item(),\n",
    "        \"f1\": ((epe > 3) & (relative_epe > 0.05)).float().mean().item() * 100,\n",
    "    }\n",
    "    return metrics, epe.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119675a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e138592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "class SameRandomCrop(torchvision.transforms.RandomCrop):\n",
    "    def __init__(self, size):\n",
    "        super().__init__(size)\n",
    "        \n",
    "    def forward(self, img1, img2, flow):\n",
    "        i, j, h, w = self.get_params(img1, self.size)\n",
    "        \n",
    "        return F.crop(img1, i, j, h, w), F.crop(img2, i, j, h, w), F.crop(flow, i, j, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7150a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSintel(torchvision.datasets.Sintel):\n",
    "    def __init__(self, root):\n",
    "        super().__init__(root=root)\n",
    "        self.crop = SameRandomCrop((368, 768))\n",
    "        self.toTensor = torchvision.transforms.ToTensor()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img1, img2, flow = super().__getitem__(index)\n",
    "        img1 = self.toTensor(img1)\n",
    "        img2 = self.toTensor(img2)\n",
    "        flow = torch.from_numpy(flow)\n",
    "        img1, img2, flow = self.crop(img1, img2, flow)\n",
    "        valid_flow_mask = torch.ones(flow.shape[1:]).to(torch.bool)\n",
    "        return img1, img2, flow, valid_flow_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc026659",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TSintel(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171fffed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f16a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(data) * 0.8)\n",
    "test_size = round(len(data) * 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27cd6325",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = torch.utils.data.random_split(data, [train_size, test_size], generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87352a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672557dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66afd686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAFT(\n",
       "  (feature_encoder): FeatureEncoder(\n",
       "    (convnormrelu): ConvNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvNormActivation(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): InstanceNorm2d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (context_encoder): FeatureEncoder(\n",
       "    (convnormrelu): ConvNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (layer1): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvNormActivation(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvNormActivation(\n",
       "          (0): Conv2d(64, 96, kernel_size=(1, 1), stride=(2, 2))\n",
       "        )\n",
       "      )\n",
       "      (1): BottleneckBlock(\n",
       "        (convnormrelu1): ConvNormActivation(\n",
       "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu2): ConvNormActivation(\n",
       "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (convnormrelu3): ConvNormActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Identity()\n",
       "      )\n",
       "    )\n",
       "    (conv): Conv2d(96, 160, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (corr_block): CorrBlock()\n",
       "  (update_block): UpdateBlock(\n",
       "    (motion_encoder): MotionEncoder(\n",
       "      (convcorr1): ConvNormActivation(\n",
       "        (0): Conv2d(196, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (convcorr2): Identity()\n",
       "      (convflow1): ConvNormActivation(\n",
       "        (0): Conv2d(2, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (convflow2): ConvNormActivation(\n",
       "        (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv): ConvNormActivation(\n",
       "        (0): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (recurrent_block): RecurrentBlock(\n",
       "      (convgru1): ConvGRU(\n",
       "        (convz): Conv2d(242, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (convr): Conv2d(242, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (convq): Conv2d(242, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (flow_head): FlowHead(\n",
       "      (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.optical_flow.raft_small()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "662fe5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "epochs = 50\n",
    "weight_decay = 5e-5\n",
    "eps = 1e-8\n",
    "num_train_flow_updates = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b745170",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, eps=eps)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=lr,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    pct_start=0.05,\n",
    "    cycle_momentum=False,\n",
    "    anneal_strategy=\"linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93fb3da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "0 5\n",
      "0 6\n",
      "0 7\n",
      "0 8\n",
      "0 9\n",
      "0 10\n",
      "0 11\n",
      "0 12\n",
      "0 13\n",
      "0 14\n",
      "0 15\n",
      "0 16\n",
      "0 17\n",
      "0 18\n",
      "0 19\n",
      "0 20\n",
      "0 21\n",
      "0 22\n",
      "0 23\n",
      "0 24\n",
      "0 25\n",
      "0 26\n",
      "0 27\n",
      "0 28\n",
      "0 29\n",
      "0 30\n",
      "0 31\n",
      "0 32\n",
      "0 33\n",
      "0 34\n",
      "0 35\n",
      "0 36\n",
      "0 37\n",
      "0 38\n",
      "0 39\n",
      "0 40\n",
      "0 41\n",
      "0 42\n",
      "0 43\n",
      "0 44\n",
      "0 45\n",
      "0 46\n",
      "0 47\n",
      "0 48\n",
      "0 49\n",
      "0 50\n",
      "0 51\n",
      "0 52\n",
      "0 53\n",
      "0 54\n",
      "0 55\n",
      "0 56\n",
      "0 57\n",
      "0 58\n",
      "0 59\n",
      "0 60\n",
      "0 61\n",
      "0 62\n",
      "0 63\n",
      "0 64\n",
      "0 65\n",
      "0 66\n",
      "0 67\n",
      "0 68\n",
      "0 69\n",
      "0 70\n",
      "0 71\n",
      "0 72\n",
      "0 73\n",
      "0 74\n",
      "0 75\n",
      "0 76\n",
      "0 77\n",
      "0 78\n",
      "0 79\n",
      "0 80\n",
      "0 81\n",
      "0 82\n",
      "0 83\n",
      "0 84\n",
      "0 85\n",
      "0 86\n",
      "0 87\n",
      "0 88\n",
      "0 89\n",
      "0 90\n",
      "0 91\n",
      "0 92\n",
      "0 93\n",
      "0 94\n",
      "0 95\n",
      "0 96\n",
      "0 97\n",
      "0 98\n",
      "0 99\n",
      "0 100\n",
      "0 101\n",
      "0 102\n",
      "0 103\n",
      "0 104\n",
      "0 105\n",
      "0 106\n",
      "0 107\n",
      "0 108\n",
      "0 109\n",
      "0 110\n",
      "0 111\n",
      "0 112\n",
      "0 113\n",
      "0 114\n",
      "0 115\n",
      "0 116\n",
      "0 117\n",
      "0 118\n",
      "0 119\n",
      "0 120\n",
      "0 121\n",
      "0 122\n",
      "0 123\n",
      "0 124\n",
      "0 125\n",
      "0 126\n",
      "0 127\n",
      "0 128\n",
      "0 129\n",
      "0 130\n",
      "0 131\n",
      "0 132\n",
      "0 133\n",
      "0 134\n",
      "0 135\n",
      "0 136\n",
      "0 137\n",
      "0 138\n",
      "0 139\n",
      "0 140\n",
      "0 141\n",
      "0 142\n",
      "0 143\n",
      "0 144\n",
      "0 145\n",
      "0 146\n",
      "0 147\n",
      "0 148\n",
      "0 149\n",
      "0 150\n",
      "0 151\n",
      "0 152\n",
      "0 153\n",
      "0 154\n",
      "0 155\n",
      "0 156\n",
      "0 157\n",
      "0 158\n",
      "0 159\n",
      "0 160\n",
      "0 161\n",
      "0 162\n",
      "0 163\n",
      "0 164\n",
      "0 165\n",
      "0 166\n",
      "0 167\n",
      "0 168\n",
      "0 169\n",
      "0 170\n",
      "0 171\n",
      "0 172\n",
      "0 173\n",
      "0 174\n",
      "0 175\n",
      "0 176\n",
      "0 177\n",
      "0 178\n",
      "0 179\n",
      "0 180\n",
      "0 181\n",
      "0 182\n",
      "0 183\n",
      "0 184\n",
      "0 185\n",
      "0 186\n",
      "0 187\n",
      "0 188\n",
      "0 189\n",
      "0 190\n",
      "0 191\n",
      "0 192\n",
      "0 193\n",
      "0 194\n",
      "0 195\n",
      "0 196\n",
      "0 197\n",
      "0 198\n",
      "0 199\n",
      "0 200\n",
      "0 201\n",
      "0 202\n",
      "0 203\n",
      "0 204\n",
      "0 205\n",
      "0 206\n",
      "0 207\n",
      "0 208\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "1 5\n",
      "1 6\n",
      "1 7\n",
      "1 8\n",
      "1 9\n",
      "1 10\n",
      "1 11\n",
      "1 12\n",
      "1 13\n",
      "1 14\n",
      "1 15\n",
      "1 16\n",
      "1 17\n",
      "1 18\n",
      "1 19\n",
      "1 20\n",
      "1 21\n",
      "1 22\n",
      "1 23\n",
      "1 24\n",
      "1 25\n",
      "1 26\n",
      "1 27\n",
      "1 28\n",
      "1 29\n",
      "1 30\n",
      "1 31\n",
      "1 32\n",
      "1 33\n",
      "1 34\n",
      "1 35\n",
      "1 36\n",
      "1 37\n",
      "1 38\n",
      "1 39\n",
      "1 40\n",
      "1 41\n",
      "1 42\n",
      "1 43\n",
      "1 44\n",
      "1 45\n",
      "1 46\n",
      "1 47\n",
      "1 48\n",
      "1 49\n",
      "1 50\n",
      "1 51\n",
      "1 52\n",
      "1 53\n",
      "1 54\n",
      "1 55\n",
      "1 56\n",
      "1 57\n",
      "1 58\n",
      "1 59\n",
      "1 60\n",
      "1 61\n",
      "1 62\n",
      "1 63\n",
      "1 64\n",
      "1 65\n",
      "1 66\n",
      "1 67\n",
      "1 68\n",
      "1 69\n",
      "1 70\n",
      "1 71\n",
      "1 72\n",
      "1 73\n",
      "1 74\n",
      "1 75\n",
      "1 76\n",
      "1 77\n",
      "1 78\n",
      "1 79\n",
      "1 80\n",
      "1 81\n",
      "1 82\n",
      "1 83\n",
      "1 84\n",
      "1 85\n",
      "1 86\n",
      "1 87\n",
      "1 88\n",
      "1 89\n",
      "1 90\n",
      "1 91\n",
      "1 92\n",
      "1 93\n",
      "1 94\n",
      "1 95\n",
      "1 96\n",
      "1 97\n",
      "1 98\n",
      "1 99\n",
      "1 100\n",
      "1 101\n",
      "1 102\n",
      "1 103\n",
      "1 104\n",
      "1 105\n",
      "1 106\n",
      "1 107\n",
      "1 108\n",
      "1 109\n",
      "1 110\n",
      "1 111\n",
      "1 112\n",
      "1 113\n",
      "1 114\n",
      "1 115\n",
      "1 116\n",
      "1 117\n",
      "1 118\n",
      "1 119\n",
      "1 120\n",
      "1 121\n",
      "1 122\n",
      "1 123\n",
      "1 124\n",
      "1 125\n",
      "1 126\n",
      "1 127\n",
      "1 128\n",
      "1 129\n",
      "1 130\n",
      "1 131\n",
      "1 132\n",
      "1 133\n",
      "1 134\n",
      "1 135\n",
      "1 136\n",
      "1 137\n",
      "1 138\n",
      "1 139\n",
      "1 140\n",
      "1 141\n",
      "1 142\n",
      "1 143\n",
      "1 144\n",
      "1 145\n",
      "1 146\n",
      "1 147\n",
      "1 148\n",
      "1 149\n",
      "1 150\n",
      "1 151\n",
      "1 152\n",
      "1 153\n",
      "1 154\n",
      "1 155\n",
      "1 156\n",
      "1 157\n",
      "1 158\n",
      "1 159\n",
      "1 160\n",
      "1 161\n",
      "1 162\n",
      "1 163\n",
      "1 164\n",
      "1 165\n",
      "1 166\n",
      "1 167\n",
      "1 168\n",
      "1 169\n",
      "1 170\n",
      "1 171\n",
      "1 172\n",
      "1 173\n",
      "1 174\n",
      "1 175\n",
      "1 176\n",
      "1 177\n",
      "1 178\n",
      "1 179\n",
      "1 180\n",
      "1 181\n",
      "1 182\n",
      "1 183\n",
      "1 184\n",
      "1 185\n",
      "1 186\n",
      "1 187\n",
      "1 188\n",
      "1 189\n",
      "1 190\n",
      "1 191\n",
      "1 192\n",
      "1 193\n",
      "1 194\n",
      "1 195\n",
      "1 196\n",
      "1 197\n",
      "1 198\n",
      "1 199\n",
      "1 200\n",
      "1 201\n",
      "1 202\n",
      "1 203\n",
      "1 204\n",
      "1 205\n",
      "1 206\n",
      "1 207\n",
      "1 208\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "2 5\n",
      "2 6\n",
      "2 7\n",
      "2 8\n",
      "2 9\n",
      "2 10\n",
      "2 11\n",
      "2 12\n",
      "2 13\n",
      "2 14\n",
      "2 15\n",
      "2 16\n",
      "2 17\n",
      "2 18\n",
      "2 19\n",
      "2 20\n",
      "2 21\n",
      "2 22\n",
      "2 23\n",
      "2 24\n",
      "2 25\n",
      "2 26\n",
      "2 27\n",
      "2 28\n",
      "2 29\n",
      "2 30\n",
      "2 31\n",
      "2 32\n",
      "2 33\n",
      "2 34\n",
      "2 35\n",
      "2 36\n",
      "2 37\n",
      "2 38\n",
      "2 39\n",
      "2 40\n",
      "2 41\n",
      "2 42\n",
      "2 43\n",
      "2 44\n",
      "2 45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m image1, image2, flow_gt, valid_flow_mask \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data_blob)\n\u001b[0;32m----> 7\u001b[0m flow_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_flow_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_train_flow_updates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m sequence_loss(flow_predictions, flow_gt, valid_flow_mask)\n\u001b[1;32m     10\u001b[0m metrics, _ \u001b[38;5;241m=\u001b[39m compute_metrics(flow_predictions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], flow_gt, valid_flow_mask)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.9/site-packages/torchvision/models/optical_flow/raft.py:487\u001b[0m, in \u001b[0;36mRAFT.forward\u001b[0;34m(self, image1, image2, num_flow_updates)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_flow_updates):\n\u001b[1;32m    486\u001b[0m     coords1 \u001b[38;5;241m=\u001b[39m coords1\u001b[38;5;241m.\u001b[39mdetach()  \u001b[38;5;66;03m# Don't backpropagate gradients through this branch, see paper\u001b[39;00m\n\u001b[0;32m--> 487\u001b[0m     corr_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_pyramid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentroids_coords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoords1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m     flow \u001b[38;5;241m=\u001b[39m coords1 \u001b[38;5;241m-\u001b[39m coords0\n\u001b[1;32m    490\u001b[0m     hidden_state, delta_flow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block(hidden_state, context, corr_features, flow)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs231n/lib/python3.9/site-packages/torchvision/models/optical_flow/raft.py:367\u001b[0m, in \u001b[0;36mCorrBlock.index_pyramid\u001b[0;34m(self, centroids_coords)\u001b[0m\n\u001b[1;32m    365\u001b[0m di \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius, neighborhood_side_len)\n\u001b[1;32m    366\u001b[0m dj \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mradius, neighborhood_side_len)\n\u001b[0;32m--> 367\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeshgrid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mij\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentroids_coords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m delta \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, neighborhood_side_len, neighborhood_side_len, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    370\u001b[0m batch_size, _, h, w \u001b[38;5;241m=\u001b[39m centroids_coords\u001b[38;5;241m.\u001b[39mshape  \u001b[38;5;66;03m# _ = 2\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    for i, data_blob in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        image1, image2, flow_gt, valid_flow_mask = (x.to(device) for x in data_blob)\n",
    "        flow_predictions = model(image1, image2, num_flow_updates=num_train_flow_updates)\n",
    "\n",
    "        loss = sequence_loss(flow_predictions, flow_gt, valid_flow_mask)\n",
    "        metrics, epe = compute_metrics(flow_predictions[-1], flow_gt, valid_flow_mask)\n",
    "\n",
    "        metrics.pop(\"f1\")\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9369c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "cs231n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
