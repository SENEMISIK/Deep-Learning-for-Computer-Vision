{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5728ebd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cs231n/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/cs231n/util.py:11: ImportWarning: failed to load custom correlation modulewhich is needed for FlowNetC\n",
      "  warnings.warn(\"failed to load custom correlation module\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from utils import compute_metrics, sequence_loss, InputPadder\n",
    "from presets import OpticalFlowPresetTrain, OpticalFlowPresetEval\n",
    "from model import FlowNetS\n",
    "from multiscaleloss import multiscaleEPE, realEPE\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcebadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"raft\"\n",
    "pretrain_size = 10\n",
    "finetune_size = 520\n",
    "pretrain=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d20d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(pretrain_size, finetune_size):\n",
    "    fc_transforms = OpticalFlowPresetTrain(crop_size=(368, 496), min_scale=0.1, max_scale=1.0, do_flip=True)\n",
    "    flying_chairs = torchvision.datasets.FlyingChairs(root=\".\", split=\"train\", transforms=fc_transforms)\n",
    "    s_transforms = OpticalFlowPresetTrain(crop_size=(368, 768), min_scale=-0.2, max_scale=0.6, do_flip=True)\n",
    "    sintel_train = torchvision.datasets.Sintel(root=\".\", split=\"train\", pass_name=\"clean\", transforms=s_transforms)\n",
    "    test_transforms = OpticalFlowPresetEval()\n",
    "    sintel_test = torchvision.datasets.Sintel(root=\".\", split=\"train\", pass_name=\"clean\", transforms=test_transforms)\n",
    "\n",
    "    train_ind = np.random.choice(len(sintel_train), finetune_size, replace=False)[:10]\n",
    "    test_ind = np.array(list(set(range(len(sintel_train))) - set(train_ind)))[:50]\n",
    "    fc_ind = np.random.choice(len(flying_chairs), pretrain_size, replace=False)\n",
    "\n",
    "    sintel_train = torch.utils.data.Subset(sintel_train, train_ind)\n",
    "    sintel_test = torch.utils.data.Subset(sintel_test, test_ind)\n",
    "    fc_pretrain = torch.utils.data.Subset(flying_chairs, fc_ind)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(sintel_train, batch_size=10, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(sintel_test, batch_size=10, shuffle=False)\n",
    "    fc_loader = torch.utils.data.DataLoader(fc_pretrain, batch_size=10, shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader, fc_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e29ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4513ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flownet_one_epoch(model, train_loader, optimizer, scheduler, device, epoch):\n",
    "    start = time.time()\n",
    "    epoch_loss = 0.0\n",
    "    for i, data_blob in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        image1, image2, flow_gt, valid_flow_mask = (x.to(device) for x in data_blob)\n",
    "        image = torch.cat((image1, image2), dim=1)\n",
    "        \n",
    "        output = model(image)\n",
    "\n",
    "        loss = multiscaleEPE(output, flow_gt)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute epe loss \n",
    "        h, w = flow_gt.size()[-2:]\n",
    "        upsampled_output = torch.nn.functional.interpolate(output[0], (h,w), mode='bilinear', align_corners=False)\n",
    "        metrics, _ = compute_metrics(upsampled_output, flow_gt)\n",
    "        epoch_loss += metrics[\"epe\"]\n",
    "            \n",
    "    scheduler.step()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(\"Epoch\", epoch + 1, \"finished in\", round(time.time() - start, 1), \"seconds. Loss:\", epoch_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17117435",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_flownet(fc_loader, train_loader, pretrain=True):\n",
    "    pretrain_epochs = 100\n",
    "    finetune_epochs = 20\n",
    "    lr = 1e-4\n",
    "    weight_decay = 4e-4\n",
    "    model = FlowNetS()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    model = model.to(device)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 75, 100, 110], gamma=0.5)\n",
    "\n",
    "    model.train()\n",
    "    pretrain_losses = []\n",
    "    finetune_losses = []\n",
    "    if pretrain:\n",
    "        print(\"Pretraining FlowNet on\", len(fc_loader.dataset), \"FlyingChairs examples...\")\n",
    "        for epoch in range(pretrain_epochs):\n",
    "            pretrain_losses.append(train_flownet_one_epoch(model, fc_loader, optimizer, scheduler, device, epoch))\n",
    "    print(\"Finetuning Flownet on\", len(train_loader.dataset), \"Sintel examples...\")\n",
    "    for epoch in range(finetune_epochs):\n",
    "        finetune_losses.append(train_flownet_one_epoch(model, train_loader, optimizer, scheduler, device, epoch))\n",
    "    return model, pretrain_losses, finetune_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a4fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flownet(model, test_loader):\n",
    "    model.eval()\n",
    "    total_epe = 0.0\n",
    "    total_f1 = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data_blob in enumerate(test_loader):\n",
    "            image1, image2, flow_gt, valid_flow_mask = (x.to(device) for x in data_blob)\n",
    "            image = torch.cat((image1, image2), dim=1)\n",
    "\n",
    "            output = model(image)\n",
    "            h, w = flow_gt.size()[-2:]\n",
    "            upsampled_output = torch.nn.functional.interpolate(output, (h,w), mode='bilinear', align_corners=False)\n",
    "            metrics, _ = compute_metrics(upsampled_output, flow_gt, valid_flow_mask)\n",
    "            epe = metrics[\"epe\"]\n",
    "            f1 = metrics[\"f1\"]\n",
    "\n",
    "            total_epe += epe\n",
    "            total_f1 += f1\n",
    "\n",
    "    total_epe /= len(test_loader)\n",
    "    total_f1 /= len(test_loader)\n",
    "    \n",
    "    return total_epe, total_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286f3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raft(fc_loader, train_loader, pretrain=True):\n",
    "    model = torchvision.models.optical_flow.raft_small()\n",
    "    model.to(device)\n",
    "    pretrain_epochs = 20\n",
    "    finetune_epochs = 10\n",
    "\n",
    "    lr = 2e-5\n",
    "    weight_decay = 5e-5\n",
    "    eps = 1e-8\n",
    "    num_train_flow_updates = 12\n",
    "    \n",
    "    total_steps = finetune_epochs * len(train_loader)\n",
    "    if pretrain:\n",
    "        total_steps += pretrain_epochs * len(fc_loader)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, eps=eps)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=lr,\n",
    "        total_steps=total_steps,\n",
    "        pct_start=0.05,\n",
    "        cycle_momentum=False,\n",
    "        anneal_strategy=\"linear\",\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    pretrain_losses = []\n",
    "    finetune_losses = []\n",
    "    if pretrain:\n",
    "        print(\"Pretraining RAFT on\", len(fc_loader.dataset), \"FlyingChairs examples...\")\n",
    "        for epoch in range(pretrain_epochs):\n",
    "            pretrain_losses.append(train_raft_one_epoch(model, fc_loader, optimizer, scheduler, device, epoch, num_train_flow_updates))\n",
    "    print(\"Finetuning RAFT on\", len(train_loader.dataset), \"Sintel examples...\")\n",
    "    for epoch in range(finetune_epochs):\n",
    "        finetune_losses.append(train_raft_one_epoch(model, train_loader, optimizer, scheduler, device, epoch, num_train_flow_updates))\n",
    "    return model, pretrain_losses, finetune_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c151c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raft_one_epoch(model, train_loader, optimizer, scheduler, device, epoch, num_train_flow_updates):\n",
    "    start = time.time()\n",
    "    epoch_loss = 0.0\n",
    "    for i, data_blob in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        image1, image2, flow_gt, valid_flow_mask = (x.to(device) for x in data_blob)\n",
    "        flow_predictions = model(image1, image2, num_flow_updates=num_train_flow_updates)\n",
    "\n",
    "        loss = sequence_loss(flow_predictions, flow_gt, valid_flow_mask)\n",
    "        metrics, epe_num = compute_metrics(flow_predictions[-1], flow_gt, valid_flow_mask)\n",
    "\n",
    "        epoch_loss += metrics[\"epe\"]\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(\"Epoch\", epoch + 1, \"finished in\", round(time.time() - start, 1), \"seconds. Loss:\", epoch_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461076fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raft(model, test_loader, num_test_updates=32):\n",
    "    model.eval()\n",
    "    total_epe = 0.0\n",
    "    total_f1 = 0.0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data_blob in enumerate(test_loader):\n",
    "            image1, image2, flow_gt = (x.to(device) for x in data_blob)\n",
    "            padder = InputPadder(image1.shape)\n",
    "            image1, image2 = padder.pad(image1, image2)\n",
    "\n",
    "            flow_predictions = model(image1, image2, num_flow_updates=num_test_updates)\n",
    "            flow_pred = flow_predictions[-1]\n",
    "            flow_pred = padder.unpad(flow_pred)\n",
    "            \n",
    "            metrics, _ = compute_metrics(flow_pred, flow_gt)\n",
    "            epe = metrics[\"epe\"]\n",
    "            f1 = metrics[\"f1\"]\n",
    "\n",
    "            total_epe += epe\n",
    "            total_f1 += f1\n",
    "\n",
    "    total_epe /= len(test_loader)\n",
    "    total_f1 /= len(test_loader)\n",
    "    \n",
    "    return total_epe, total_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e02c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(results, model_type, pretrain_size):\n",
    "    path = os.path.join(\"results\", model_type + str(pretrain_size) + \"_results.txt\")\n",
    "    torch.save(results, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a3627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_type, pretrain_size):\n",
    "    path = os.path.join(\"results\", model_type + str(pretrain_size) + \"_params.pt\")\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e6230c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuning RAFT on 10 Sintel examples...\n",
      "Epoch 1 finished in 4.1 seconds. Loss: 24.054672241210938\n",
      "Epoch 2 finished in 4.5 seconds. Loss: 23.740591049194336\n",
      "Epoch 3 finished in 3.9 seconds. Loss: 22.062257766723633\n",
      "Epoch 4 finished in 4.2 seconds. Loss: 21.060420989990234\n",
      "Epoch 5 finished in 4.2 seconds. Loss: 20.879302978515625\n",
      "Epoch 6 finished in 3.9 seconds. Loss: 24.18783187866211\n",
      "Epoch 7 finished in 4.3 seconds. Loss: 24.239057540893555\n",
      "Epoch 8 finished in 3.9 seconds. Loss: 21.87493324279785\n",
      "Epoch 9 finished in 4.0 seconds. Loss: 20.071794509887695\n",
      "Epoch 10 finished in 4.1 seconds. Loss: 22.1276912689209\n",
      "Test:\n",
      "Epe:  30.536666107177734\n",
      "F1:  98.31702947616577\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader, fc_loader = get_data(pretrain_size, finetune_size)\n",
    "\n",
    "\n",
    "if model_type == \"flownet\":    \n",
    "    model, pretrain_losses, finetune_losses = train_flownet(fc_loader, train_loader, pretrain)\n",
    "    epe, f1 = test_flownet(model, test_loader)\n",
    "    print(\"Test:\")\n",
    "    print(\"Epe: \", epe)\n",
    "    print(\"F1: \", f1)\n",
    "    results = {\n",
    "        \"pretrain_losses\": pretrain_losses, \n",
    "        \"finetune_losses\": finetune_losses,\n",
    "        \"epe\": epe,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    if not pretrain:\n",
    "        pretrain_size = 0\n",
    "    save_results(results, model_type, pretrain_size)\n",
    "    save_model(model, model_type, pretrain_size)\n",
    "elif model_type == \"raft\":\n",
    "    model, pretrain_losses, finetune_losses = train_raft(fc_loader, train_loader, pretrain)\n",
    "    epe, f1 = test_raft(model, test_loader)\n",
    "    print(\"Test:\")\n",
    "    print(\"Epe: \", epe)\n",
    "    print(\"F1: \", f1)\n",
    "    results = {\n",
    "        \"pretrain_losses\": pretrain_losses, \n",
    "        \"finetune_losses\": finetune_losses,\n",
    "        \"epe\": epe,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "    if not pretrain:\n",
    "        pretrain_size = 0\n",
    "    save_results(results, model_type, pretrain_size)\n",
    "    save_model(model, model_type, pretrain_size)\n",
    "else:\n",
    "    raise(Exception(\"Invalid model type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d2f5a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5d28deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrain_losses': [],\n",
       " 'finetune_losses': [51.80144500732422,\n",
       "  43.32882308959961,\n",
       "  30.19902801513672,\n",
       "  30.44305992126465,\n",
       "  28.65836524963379,\n",
       "  30.460718154907227,\n",
       "  26.02287483215332,\n",
       "  23.477127075195312,\n",
       "  24.884212493896484,\n",
       "  26.327390670776367],\n",
       " 'epe': 34.20448265075684,\n",
       " 'f1': 99.13549184799194}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"results/raft0_results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1adbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "cs231n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
