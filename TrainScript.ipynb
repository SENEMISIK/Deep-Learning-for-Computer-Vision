{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5728ebd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cs231n/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/cs231n/util.py:11: ImportWarning: failed to load custom correlation modulewhich is needed for FlowNetC\n",
      "  warnings.warn(\"failed to load custom correlation module\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from utils import compute_metrics, sequence_loss, InputPadder\n",
    "from presets import OpticalFlowPresetTrain, OpticalFlowPresetEval\n",
    "from model import FlowNetS\n",
    "from multiscaleloss import multiscaleEPE, realEPE\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcebadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"raft\"\n",
    "pretrain_size = 10\n",
    "finetune_size = 520"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45378f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_transforms = OpticalFlowPresetTrain(crop_size=(368, 496), min_scale=0.1, max_scale=1.0, do_flip=True)\n",
    "flying_chairs = torchvision.datasets.FlyingChairs(root=\".\", split=\"train\", transforms=fc_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f65d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_transforms = OpticalFlowPresetTrain(crop_size=(368, 768), min_scale=-0.2, max_scale=0.6, do_flip=True)\n",
    "sintel_train = torchvision.datasets.Sintel(root=\".\", split=\"train\", pass_name=\"clean\", transforms=s_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9211709",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = OpticalFlowPresetEval()\n",
    "sintel_test = torchvision.datasets.Sintel(root=\".\", split=\"train\", pass_name=\"clean\", transforms=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e799a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = np.random.choice(len(sintel_train), finetune_size, replace=False)[:10]\n",
    "test_ind = np.array(list(set(range(len(sintel_train))) - set(train_ind)))[:50]\n",
    "fc_ind = np.random.choice(len(flying_chairs), pretrain_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b1fa6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sintel_train = torch.utils.data.Subset(sintel_train, train_ind)\n",
    "sintel_test = torch.utils.data.Subset(sintel_test, test_ind)\n",
    "fc_pretrain = torch.utils.data.Subset(flying_chairs, fc_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50d7993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(sintel_train, batch_size=10, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(sintel_test, batch_size=10, shuffle=False)\n",
    "fc_loader = torch.utils.data.DataLoader(fc_pretrain, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e29ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4513ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_flownet_one_epoch(model, train_loader, optimizer, scheduler, device, epoch):\n",
    "    start = time.time()\n",
    "    epoch_loss = 0.0\n",
    "    for i, data_blob in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        image1, image2, flow_gt, valid_flow_mask = (x.to(device) for x in data_blob)\n",
    "        image = torch.cat((image1, image2), dim=1)\n",
    "        \n",
    "        output = model(image)\n",
    "\n",
    "        loss = multiscaleEPE(output, flow_gt)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute epe loss \n",
    "        h, w = flow_gt.size()[-2:]\n",
    "        upsampled_output = torch.nn.functional.interpolate(output[0], (h,w), mode='bilinear', align_corners=False)\n",
    "        metrics, _ = compute_metrics(upsampled_output, flow_gt)\n",
    "        epoch_loss += metrics[\"epe\"]\n",
    "            \n",
    "    scheduler.step()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(\"Epoch\", epoch + 1, \"finished in\", round(time.time() - start, 1), \"seconds. Loss:\", epoch_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17117435",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_flownet(fc_loader, train_loader):\n",
    "    pretrain_epochs = 100\n",
    "    finetune_epochs = 20\n",
    "    lr = 1e-4\n",
    "    weight_decay = 4e-4\n",
    "    model = FlowNetS()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    model = model.to(device)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 75, 100, 110], gamma=0.5)\n",
    "\n",
    "    model.train()\n",
    "    pretrain_losses = []\n",
    "    finetune_losses = []\n",
    "    print(\"Pretraining FlowNet on\", len(fc_loader.dataset), \"FlyingChairs examples...\")\n",
    "    for epoch in range(pretrain_epochs):\n",
    "        pretrain_losses.append(train_flownet_one_epoch(model, fc_loader, optimizer, scheduler, device, epoch))\n",
    "    print(\"Finetuning Flownet on\", len(train_loader.dataset), \"Sintel examples...\")\n",
    "    for epoch in range(finetune_epochs):\n",
    "        finetune_losses.append(train_flownet_one_epoch(model, train_loader, optimizer, scheduler, device, epoch))\n",
    "    return model, pretrain_losses, finetune_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10a4fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_flownet(model, test_loader):\n",
    "    model.eval()\n",
    "    total_epe = 0.0\n",
    "    total_f1 = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data_blob in enumerate(test_loader):\n",
    "            image1, image2, flow_gt, valid_flow_mask = (x.to(device) for x in data_blob)\n",
    "            image = torch.cat((image1, image2), dim=1)\n",
    "\n",
    "            output = model(image)\n",
    "            h, w = flow_gt.size()[-2:]\n",
    "            upsampled_output = torch.nn.functional.interpolate(output, (h,w), mode='bilinear', align_corners=False)\n",
    "            metrics, _ = compute_metrics(upsampled_output, flow_gt, valid_flow_mask)\n",
    "            epe = metrics[\"epe\"]\n",
    "            f1 = metrics[\"f1\"]\n",
    "\n",
    "            total_epe += epe\n",
    "            total_f1 += f1\n",
    "\n",
    "    total_epe /= len(test_loader)\n",
    "    total_f1 /= len(test_loader)\n",
    "    \n",
    "    return total_epe, total_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "286f3704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raft(fc_loader, train_loader):\n",
    "    model = torchvision.models.optical_flow.raft_small()\n",
    "    model.to(device)\n",
    "    pretrain_epochs = 20\n",
    "    finetune_epochs = 10\n",
    "\n",
    "    lr = 2e-5\n",
    "    weight_decay = 5e-5\n",
    "    eps = 1e-8\n",
    "    num_train_flow_updates = 12\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, eps=eps)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=lr,\n",
    "        total_steps= pretrain_epochs * len(fc_loader) + finetune_epochs * len(train_loader),\n",
    "        pct_start=0.05,\n",
    "        cycle_momentum=False,\n",
    "        anneal_strategy=\"linear\",\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    pretrain_losses = []\n",
    "    finetune_losses = []\n",
    "    print(\"Pretraining RAFT on\", len(fc_loader.dataset), \"FlyingChairs examples...\")\n",
    "    for epoch in range(pretrain_epochs):\n",
    "        pretrain_losses.append(train_raft_one_epoch(model, fc_loader, optimizer, scheduler, device, epoch, num_train_flow_updates))\n",
    "    print(\"Finetuning RAFT on\", len(train_loader.dataset), \"Sintel examples...\")\n",
    "    for epoch in range(finetune_epochs):\n",
    "        finetune_losses.append(train_raft_one_epoch(model, train_loader, optimizer, scheduler, device, epoch, num_train_flow_updates))\n",
    "    return model, pretrain_losses, finetune_losses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c151c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raft_one_epoch(model, train_loader, optimizer, scheduler, device, epoch, num_train_flow_updates):\n",
    "    start = time.time()\n",
    "    epoch_loss = 0.0\n",
    "    for i, data_blob in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        image1, image2, flow_gt, valid_flow_mask = (x.to(device) for x in data_blob)\n",
    "        flow_predictions = model(image1, image2, num_flow_updates=num_train_flow_updates)\n",
    "\n",
    "        loss = sequence_loss(flow_predictions, flow_gt, valid_flow_mask)\n",
    "        metrics, epe_num = compute_metrics(flow_predictions[-1], flow_gt, valid_flow_mask)\n",
    "\n",
    "        epoch_loss += metrics[\"epe\"]\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(\"Epoch\", epoch + 1, \"finished in\", round(time.time() - start, 1), \"seconds. Loss:\", epoch_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "461076fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raft(model, test_loader, num_test_updates=32):\n",
    "    model.eval()\n",
    "    total_epe = 0.0\n",
    "    total_f1 = 0.0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data_blob in enumerate(test_loader):\n",
    "            image1, image2, flow_gt = (x.to(device) for x in data_blob)\n",
    "            padder = InputPadder(image1.shape)\n",
    "            image1, image2 = padder.pad(image1, image2)\n",
    "\n",
    "            flow_predictions = model(image1, image2, num_flow_updates=num_test_updates)\n",
    "            flow_pred = flow_predictions[-1]\n",
    "            flow_pred = padder.unpad(flow_pred)\n",
    "            \n",
    "            metrics, _ = compute_metrics(flow_pred, flow_gt, valid_flow_mask)\n",
    "            epe = metrics[\"epe\"]\n",
    "            f1 = metrics[\"f1\"]\n",
    "\n",
    "            total_epe += epe\n",
    "            total_f1 += f1\n",
    "\n",
    "    total_epe /= len(test_loader)\n",
    "    total_f1 /= len(test_loader)\n",
    "    \n",
    "    return total_epe, total_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e6230c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining RAFT on 10 FlyingChairs examples...\n",
      "Epoch 1 finished in 2.4 seconds. Loss: 29.304237365722656\n",
      "Epoch 2 finished in 2.1 seconds. Loss: 25.34518051147461\n",
      "Epoch 3 finished in 1.9 seconds. Loss: 22.703886032104492\n",
      "Epoch 4 finished in 1.9 seconds. Loss: 21.501140594482422\n",
      "Epoch 5 finished in 1.9 seconds. Loss: 18.35019302368164\n",
      "Epoch 6 finished in 1.7 seconds. Loss: 17.359745025634766\n",
      "Epoch 7 finished in 2.0 seconds. Loss: 17.15929412841797\n",
      "Epoch 8 finished in 1.9 seconds. Loss: 19.292194366455078\n",
      "Epoch 9 finished in 1.7 seconds. Loss: 16.107316970825195\n",
      "Epoch 10 finished in 1.6 seconds. Loss: 16.101476669311523\n",
      "Epoch 11 finished in 1.9 seconds. Loss: 14.53821849822998\n",
      "Epoch 12 finished in 1.8 seconds. Loss: 19.32129669189453\n",
      "Epoch 13 finished in 2.0 seconds. Loss: 16.713558197021484\n",
      "Epoch 14 finished in 1.9 seconds. Loss: 15.602898597717285\n",
      "Epoch 15 finished in 1.9 seconds. Loss: 17.20895767211914\n",
      "Epoch 16 finished in 1.9 seconds. Loss: 15.020562171936035\n",
      "Epoch 17 finished in 2.3 seconds. Loss: 19.609281539916992\n",
      "Epoch 18 finished in 1.9 seconds. Loss: 19.444931030273438\n",
      "Epoch 19 finished in 1.9 seconds. Loss: 11.830214500427246\n",
      "Epoch 20 finished in 1.7 seconds. Loss: 13.30103874206543\n",
      "Finetuning RAFT on 10 Sintel examples...\n",
      "Epoch 1 finished in 4.1 seconds. Loss: 18.326160430908203\n",
      "Epoch 2 finished in 4.2 seconds. Loss: 19.00479507446289\n",
      "Epoch 3 finished in 3.9 seconds. Loss: 16.712812423706055\n",
      "Epoch 4 finished in 4.2 seconds. Loss: 21.30951690673828\n",
      "Epoch 5 finished in 4.1 seconds. Loss: 18.653461456298828\n",
      "Epoch 6 finished in 4.1 seconds. Loss: 16.789785385131836\n",
      "Epoch 7 finished in 4.0 seconds. Loss: 22.042224884033203\n",
      "Epoch 8 finished in 4.1 seconds. Loss: 23.970409393310547\n",
      "Epoch 9 finished in 4.0 seconds. Loss: 17.546688079833984\n",
      "Epoch 10 finished in 4.0 seconds. Loss: 16.459476470947266\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"flownet\":\n",
    "    model, pretrain_losses, finetune_losses = train_flownet(fc_loader, train_loader)\n",
    "elif model_type == \"raft\":\n",
    "    model, pretrain_losses, finetune_losses = train_raft(fc_loader, train_loader)\n",
    "else:\n",
    "    raise(Exception(\"Invalid model type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae5ad46",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_flow_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_raft\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mtest_raft\u001b[0;34m(model, test_loader, num_test_updates)\u001b[0m\n\u001b[1;32m     14\u001b[0m flow_pred \u001b[38;5;241m=\u001b[39m flow_predictions[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     15\u001b[0m flow_pred \u001b[38;5;241m=\u001b[39m padder\u001b[38;5;241m.\u001b[39munpad(flow_pred)\n\u001b[0;32m---> 17\u001b[0m metrics, _ \u001b[38;5;241m=\u001b[39m compute_metrics(flow_pred, flow_gt, \u001b[43mvalid_flow_mask\u001b[49m)\n\u001b[1;32m     18\u001b[0m epe \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepe\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m f1 \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_flow_mask' is not defined"
     ]
    }
   ],
   "source": [
    "test_raft(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc94c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sintel_test[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0600c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs231n",
   "language": "python",
   "name": "cs231n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
